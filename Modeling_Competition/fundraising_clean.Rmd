---
title: "fundraising code"
author: "Austin Pesina"
date: "5/14/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include=FALSE}
library(MASS)
library(tidyverse)
library(caret)
library(usdm)
library(modelr)
library(PerformanceAnalytics)
library(class)
```


```{r data}
future <- read_rds("~/Data_Mining/data/future_fundraising.rds")
fund <- read_rds("~/Data_Mining/data/fundraising.rds")

set.seed(12345)

#vars
split = 0.80
trainIndex <- createDataPartition(fund$target,p=split,list=FALSE)
train <- fund[trainIndex,]
test <- fund[-trainIndex,]
train_control <- trainControl(method="repeatedcv",number=10,repeats=3)
```



## Develop Model

```{r Develop}
glm_fit <- glm(target~., data = fund, family = "binomial")
summary(glm_fit)
coef(glm_fit)
summary(glm_fit)$coef
glm_prob <- predict(glm_fit, type = "response")
contrasts(fund$target)
glm_pred <- rep("Donor", 3000)
glm_pred[glm_prob>0.5] = "No Donor"
table(glm_pred, fund$target)
mean(glm_pred==fund$target)
```


* num_child, income, home_value, months_since_donate have lowest p-values
* months_since_donate and income have strongest association 

Logistic regression was correct 56.6% of the time on the full data set.

##Logistic Regression

```{r}
glm_fit3 <- glm(target~num_child + income + home_value + months_since_donate, data = train, family ="binomial")
glm_prob3 <- predict(glm_fit3, type = "response")
glm_pred3 <- rep("Donor", 2401)
glm_pred3[glm_prob3 > 0.5] = "No Donor"
table(glm_pred3, train$target)
mean(glm_pred3==train$target)
```

55.9% accuracy.


##LDA

```{r}
lda_fit2 <- lda(target~num_child + income + home_value + months_since_donate, data = train)
lda_fit2
lda_pred2 <- predict(lda_fit2, train)
names(lda_pred2)
lda_class2 <- lda_pred2$class
table(lda_class2, train$target)
(660+679)/2401
```

55.7% accuracy


##QDA

```{r}
qda_fit2 <- qda(target~num_child + income + home_value + months_since_donate, data = train)
qda_class2 <- predict(qda_fit, train)$class
table(qda_class2, train$target)
(994+203)/2401
```

49.8% accuracy


##KNN

```{r KNN}
knn_fit2 <- train(target~num_child + income + home_value + months_since_donate, data = train, method = "knn", trControl = train_control, preProcess = c("center", "scale"), tuneLength = 20)
knn_fit
```

53.3% accuracy, k=5


#Random Forest

```{r}
rf_fit2 <- train(target~num_child + income + home_value + months_since_donate, data = train, method = "rf", trControl = trainControl("cv", number = 10), importance = T)
rf_fit2$finalModel
(609+619)/2401
```

51.1% accuracy

##SVM

#SVM Linear

```{r}
svm_fit2 <- train(target~num_child + income + home_value + months_since_donate, data = train, method = "svmLinear", trControl = train_control, preProcess = c("center", "scale"))
svm_fit2
res9 <- as_tibble(svm_fit2$results[which.min(svm_fit$results[,2]),])
```

55.5% accuracy


#SVM Radial

```{r}
svm_rad2 <- train(target~num_child + income + home_value + months_since_donate, data = train, method = "svmRadial", trControl = train_control, preProcess = c("center", "scale"), tunelength = 20)
svm_rad2$bestTune
svm_rad2
res8 <- as_tibble(svm_rad2$results[which.min(svm_rad$results[,2]),])
```

53.6% accuracy, sigma = 0.7706276, c = 0.25


#SVM Poly

```{r}
svm_poly2 <- train(target~num_child + income + home_value + months_since_donate, data = train, method = "svmPoly", trControl = train_control, preProcess = c("center", "scale"), tuneLength = 5)
svm_poly2$bestTune
svm_poly2
svm_poly2$finalModel
res7 <- as_tibble(svm_poly2$results[which.min(svm_poly$results[,2]),])
```

```{r}
df2 <- tibble(Model=c("SVM Linear", "SVM Radial", "SVM Poly"), Accuracy =c(res9$Accuracy, res8$Accuracy, res7$Accuracy))

df2 %>% arrange(Accuracy)
```

Linear most accuracte at 55.5%